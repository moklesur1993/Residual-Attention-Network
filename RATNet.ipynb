{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RATNet(99.80).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd7zTmHWydPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "92c1511c-6675-4bf8-f756-b2c504b13bee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOef_INc5LB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a07435a1-ecbb-4ac1-95a0-23663b940424"
      },
      "source": [
        "!ls \"/content/drive/My Drive\"\n",
        "!pip install -q keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'10foldRADIO_COVID .ipynb'   CT\t\t\t    own\n",
            " Bangla_Iso\t\t     edit.ipynb\t\t   'RATNet(99.80).ipynb'\n",
            " CBAM_model.ipynb\t     EYE\t\t    Selected_model.ipynb\n",
            " CMATERdb\t\t    'Getting started.pdf'   Untitled0.ipynb\n",
            "'Colab Notebooks'\t     ISI\t\t    Untitled1.ipynb\n",
            " COVID\t\t\t     OCR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjxeiYFK5aAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "#np.random.seed(1337) \n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input/testing-daata\"))\n",
        "#print(os.listdir(\"../input/thirty-two-tr\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-JJ2zDX5ds5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07b323d1-0931-4ac4-cde8-61838d2bb5b8"
      },
      "source": [
        "# load in libaries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras import models\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras import optimizers\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "weight_decay = 1e-6\n",
        "from keras.regularizers import l2\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "earlystopping = EarlyStopping(monitor='val_loss',patience=10,verbose=1,mode='auto')\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Conv2D, Activation, MaxPool2D, Dropout, Dense, BatchNormalization, Flatten\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Average, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import l2\n",
        "from six.moves import cPickle as pickle\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPjKzjJn7YnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b463f814-2662-4664-88fd-2ab6db0f6efc"
      },
      "source": [
        "# Lets load in the data\n",
        "Xtrain = np.load('/content/drive/My Drive/ISI/ISI_D/ISI_32/Xtrain_ISIT32.npy')\n",
        "Ytrain = np.load('/content/drive/My Drive/ISI/ISI_D/ISI_32/Ytrain_ISIdigit32.npy')\n",
        "Xtest = np.load('/content/drive/My Drive/ISI/ISI_D/ISI_32/Xtest_ISIdigit32.npy')\n",
        "Ytest = np.load('/content/drive/My Drive/ISI/ISI_D/ISI_32/Ytest_ISIdigit32.npy')\n",
        "#Xvalid = np.load('/content/drive/My Drive/ISI_BC/Xvalid_BC.npy')\n",
        "#Yvalid = np.load('/content/drive/My Drive/ISI_BC/Yvalid_BC.npy')\n",
        "print('X shape : {}  Y shape: {}'.format(Xtrain.shape, Ytrain.shape))\n",
        "#print('X shape : {}  Y shape: {}'.format(Xtest.shape, Ytest.shape))\n",
        "\n",
        "#plt.imshow(X[700], cmap='gray')\n",
        "#print(Y[700]) # one-hot labels starting at zero"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape : (19392, 32, 32)  Y shape: (19392, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wK5RFHN7Fwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a data generator using Keras image preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False,  \n",
        "        rotation_range=10,  \n",
        "        zoom_range = 0.10,  \n",
        "        width_shift_range=0.10,  \n",
        "        height_shift_range=0.10,  \n",
        "        horizontal_flip=False, \n",
        "        vertical_flip=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6nhbAzY6lnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dff8aee1-e7f2-4d46-f76b-fbfb9c3aaa07"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train, Xtest, Ytrain, Ytest = train_test_split(Xtrain, Ytrain, test_size=.30)\n",
        "# add another axis representing grey-scale\n",
        "#Xvalid, Xtest, yvalid, Ytest = train_test_split(Xvalid,yvalid, test_size=0.66)\n",
        "Xtrain = Xtrain[:,:,:,np.newaxis]\n",
        "#Xvalid = Xvalid[:,:,:,np.newaxis]\n",
        "Xtest = Xtest[:,:,:,np.newaxis]\n",
        "print(Xtrain.shape)\n",
        "print(Ytrain.shape)\n",
        "print(Xtest.shape)\n",
        "print(Ytest.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19392, 32, 32, 1)\n",
            "(19392, 10)\n",
            "(4000, 32, 32, 1)\n",
            "(4000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cLJuQkt7w4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(Xtrain)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB63YRNl7gTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cbam_block(cbam_feature, ratio=8):\n",
        "    \n",
        "    cbam_feature = spatial_attention(cbam_feature)\n",
        "    return cbam_feature\n",
        "\n",
        "\n",
        "def spatial_attention(input_feature):\n",
        "    kernel_size = 7\n",
        "    \n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        channel = input_feature._keras_shape[1]\n",
        "        cbam_feature = Permute((2,3,1))(input_feature)\n",
        "    else:\n",
        "        channel = input_feature._keras_shape[-1]\n",
        "        cbam_feature = input_feature\n",
        "    \n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert avg_pool._keras_shape[-1] == 1\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert max_pool._keras_shape[-1] == 1\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "    assert concat._keras_shape[-1] == 2\n",
        "    cbam_feature = Conv2D(filters = 1,\n",
        "                    kernel_size=kernel_size,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    activation='sigmoid',\n",
        "                    kernel_initializer='he_normal',\n",
        "                    use_bias=False)(concat)\t\n",
        "    assert cbam_feature._keras_shape[-1] == 1\n",
        "    \n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
        "        \n",
        "    return multiply([input_feature, cbam_feature])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHQlYS07mx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n",
        "    shortcut = y\n",
        "\n",
        "    # down-sampling is performed with a stride of 2\n",
        "    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = LeakyReLU()(y)\n",
        "\n",
        "    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    # identity shortcuts used directly when the input and output are of the same dimensions\n",
        "    if _project_shortcut or _strides != (1, 1):\n",
        "        # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
        "        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
        "        shortcut = Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    y = add([shortcut, y])\n",
        "    y = LeakyReLU()(y)\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTIU3AgX7qdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    \n",
        "    dropRate = 0.5\n",
        "    \n",
        "    init = Input(SHAPE)\n",
        "    x = Conv2D(32, (5, 5), activation=None, padding='same')(init) \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (5, 5), activation=None, padding='same')(x) \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = cbam_block(x)\n",
        "    x = residual_block(x, 64)\n",
        "    x1 = MaxPooling2D((2,2))(x)\n",
        "    \n",
        "    x = Conv2D(128, (3, 3), activation=None, padding='same')(x1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = cbam_block(x)\n",
        "    x = residual_block(x, 128)\n",
        "    x2 = MaxPooling2D((2,2))(x)\n",
        "    \n",
        "    x = Conv2D(128, (3, 3), activation=None, padding='same')(x2)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = cbam_block(x)\n",
        "    x = residual_block(x, 128)\n",
        "    x3 = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), activation=None, padding='same')(x3)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = cbam_block(x)\n",
        "    x = residual_block(x, 256)\n",
        "    x4 = MaxPooling2D((2,2))(x)  \n",
        "    ginp1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(x1)\n",
        "    ginp2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(x2)\n",
        "    ginp3 = UpSampling2D(size=(8, 8), interpolation='bilinear')(x3)\n",
        "    ginp4 = UpSampling2D(size=(16, 16), interpolation='bilinear')(x4)\n",
        "    \n",
        "    hypercolumn = Concatenate()([ginp1, ginp2, ginp3,ginp4]) \n",
        "    gap = GlobalAveragePooling2D()(hypercolumn)\n",
        "\n",
        "    x = Dense(512, activation=None)(gap)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    x = Dense(256, activation=None)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    y = Dense(10, activation='softmax')(x)\n",
        "   \n",
        "    model = Model(init, y)\n",
        "    return model\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THlo1beK7uIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba81fbfc-aa40-44ff-918e-77f2cfb9bf0e"
      },
      "source": [
        "SHAPE=(32,32,1)\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "from albumentations import *\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import load_model, Model\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "modell = create_model()\n",
        "modell.summary()\n",
        "'''schedule = SGDRScheduler(min_lr=1e-6,\n",
        "                             max_lr=1e-3,\n",
        "                             steps_per_epoch=np.ceil(EPOCHS/BATCH_SIZE),\n",
        "                             lr_decay=0.9,\n",
        "                             cycle_length=10,\n",
        "                             mult_factor=2.)'''\n",
        "from keras.optimizers import Adam\n",
        "def compile_and_train(model, num_epochs):\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    checkPoint = ModelCheckpoint(filepath='/content/drive/My Drive/ISI/'+ model.name +'.{epoch:03d}-{loss:.5f}.hdf5', verbose=1, save_best_only=True)\n",
        "    earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              patience=30,\n",
        "                              verbose=1,\n",
        "                              mode='auto')\n",
        "    lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.75, epsilon=0.0001, patience=6, verbose=1)    \n",
        "    history = model.fit_generator(datagen.flow(Xtrain, Ytrain, batch_size=128),\n",
        "                 epochs=num_epochs,verbose=2,\n",
        "                 steps_per_epoch=64,\n",
        "                 shuffle=True,\n",
        "                 callbacks=[checkPoint,lr_reduce,earlystopping],\n",
        "                 validation_data=(Xtest, Ytest)\n",
        "                  )\n",
        "\n",
        "    #model.save_weights('/content/drive/My Drive/CMATERdb/iso_32/Test/ISo_32.hdf5')\n",
        "    model.save('/content/drive/My Drive/ISI/ISI_D/ISI_32/ISI_digit_32_model.h5')\n",
        "    return history\n",
        "                       \n",
        "s1=compile_and_train(modell,200)\n",
        "score=s1.model.evaluate(Xtest, Ytest)\n",
        "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   832         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   51264       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32, 32, 1)    0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32, 1)    0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 2)    0           lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 1)    98          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 32, 32, 64)   0           activation_2[0][0]               \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           multiply_1[0][0]                 \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 16, 16, 1)    0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 16, 16, 1)    0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 2)    0           lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 1)    98          concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 16, 16, 128)  0           activation_3[0][0]               \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 128)  0           multiply_2[0][0]                 \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 128)    0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 128)    147584      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 8, 8, 1)      0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 8, 8, 1)      0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 2)      0           lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 1)      98          concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    147584      multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 128)    0           multiply_3[0][0]                 \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 8, 8, 128)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 128)    0           leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 256)    295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4, 4, 256)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4, 4, 256)    0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 4, 4, 1)      0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 4, 4, 1)      0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4, 4, 2)      0           lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 1)      98          concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 4, 4, 256)    0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 256)    590080      multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 4, 4, 256)    1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 4, 4, 256)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 256)    590080      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4, 4, 256)    1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 256)    0           multiply_4[0][0]                 \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 4, 4, 256)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 64)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 128)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 576)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 up_sampling2d_2[0][0]            \n",
            "                                                                 up_sampling2d_3[0][0]            \n",
            "                                                                 up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 576)          0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          295424      global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 512)          0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 256)          0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2570        activation_11[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,852,882\n",
            "Trainable params: 2,847,826\n",
            "Non-trainable params: 5,056\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " - 18s - loss: 0.7196 - accuracy: 0.7583 - val_loss: 2.4961 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.49609, saving model to /content/drive/My Drive/CMATERdb/model_1.001-0.71964.hdf5\n",
            "Epoch 2/200\n",
            " - 7s - loss: 0.2009 - accuracy: 0.9349 - val_loss: 3.0007 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.49609\n",
            "Epoch 3/200\n",
            " - 7s - loss: 0.1185 - accuracy: 0.9630 - val_loss: 5.0819 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2.49609\n",
            "Epoch 4/200\n",
            " - 7s - loss: 0.1047 - accuracy: 0.9683 - val_loss: 4.9873 - val_accuracy: 0.1002\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.49609\n",
            "Epoch 5/200\n",
            " - 7s - loss: 0.0941 - accuracy: 0.9712 - val_loss: 0.4496 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.49609 to 0.44955, saving model to /content/drive/My Drive/CMATERdb/model_1.005-0.09407.hdf5\n",
            "Epoch 6/200\n",
            " - 7s - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.44955 to 0.19045, saving model to /content/drive/My Drive/CMATERdb/model_1.006-0.07426.hdf5\n",
            "Epoch 7/200\n",
            " - 7s - loss: 0.0653 - accuracy: 0.9798 - val_loss: 0.1135 - val_accuracy: 0.9607\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.19045 to 0.11347, saving model to /content/drive/My Drive/CMATERdb/model_1.007-0.06549.hdf5\n",
            "Epoch 8/200\n",
            " - 7s - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.3504 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.11347\n",
            "Epoch 9/200\n",
            " - 7s - loss: 0.0559 - accuracy: 0.9827 - val_loss: 0.0436 - val_accuracy: 0.9865\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.11347 to 0.04355, saving model to /content/drive/My Drive/CMATERdb/model_1.009-0.05579.hdf5\n",
            "Epoch 10/200\n",
            " - 7s - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.1604 - val_accuracy: 0.9465\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.04355\n",
            "Epoch 11/200\n",
            " - 7s - loss: 0.0576 - accuracy: 0.9806 - val_loss: 0.0893 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.04355\n",
            "Epoch 12/200\n",
            " - 7s - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0541 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.04355\n",
            "Epoch 13/200\n",
            " - 7s - loss: 0.0391 - accuracy: 0.9873 - val_loss: 0.0257 - val_accuracy: 0.9908\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.04355 to 0.02573, saving model to /content/drive/My Drive/CMATERdb/model_1.013-0.03914.hdf5\n",
            "Epoch 14/200\n",
            " - 7s - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0301 - val_accuracy: 0.9898\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02573\n",
            "Epoch 15/200\n",
            " - 7s - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.3791 - val_accuracy: 0.9215\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02573\n",
            "Epoch 16/200\n",
            " - 7s - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0535 - val_accuracy: 0.9835\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02573\n",
            "Epoch 17/200\n",
            " - 7s - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.0816 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02573\n",
            "Epoch 18/200\n",
            " - 7s - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0805 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02573\n",
            "Epoch 19/200\n",
            " - 7s - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02573\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
            "Epoch 20/200\n",
            " - 7s - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.0396 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02573\n",
            "Epoch 21/200\n",
            " - 7s - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.0315 - val_accuracy: 0.9900\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02573\n",
            "Epoch 22/200\n",
            " - 7s - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.02573 to 0.02008, saving model to /content/drive/My Drive/CMATERdb/model_1.022-0.02397.hdf5\n",
            "Epoch 23/200\n",
            " - 7s - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0329 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02008\n",
            "Epoch 24/200\n",
            " - 7s - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0243 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02008\n",
            "Epoch 25/200\n",
            " - 7s - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0685 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02008\n",
            "Epoch 26/200\n",
            " - 7s - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02008\n",
            "Epoch 27/200\n",
            " - 7s - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0289 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02008\n",
            "Epoch 28/200\n",
            " - 7s - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0435 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02008\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
            "Epoch 29/200\n",
            " - 7s - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0404 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02008\n",
            "Epoch 30/200\n",
            " - 7s - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0205 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02008\n",
            "Epoch 31/200\n",
            " - 7s - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.0140 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.02008 to 0.01404, saving model to /content/drive/My Drive/CMATERdb/model_1.031-0.01856.hdf5\n",
            "Epoch 32/200\n",
            " - 7s - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0249 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01404\n",
            "Epoch 33/200\n",
            " - 7s - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0269 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01404\n",
            "Epoch 34/200\n",
            " - 7s - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0719 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01404\n",
            "Epoch 35/200\n",
            " - 7s - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.0246 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01404\n",
            "Epoch 36/200\n",
            " - 7s - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0237 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01404\n",
            "Epoch 37/200\n",
            " - 7s - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0171 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01404\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
            "Epoch 38/200\n",
            " - 7s - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0209 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01404\n",
            "Epoch 39/200\n",
            " - 7s - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0181 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01404\n",
            "Epoch 40/200\n",
            " - 7s - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0340 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01404\n",
            "Epoch 41/200\n",
            " - 7s - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0114 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.01404 to 0.01136, saving model to /content/drive/My Drive/CMATERdb/model_1.041-0.01529.hdf5\n",
            "Epoch 42/200\n",
            " - 7s - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0154 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01136\n",
            "Epoch 43/200\n",
            " - 7s - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01136\n",
            "Epoch 44/200\n",
            " - 7s - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0346 - val_accuracy: 0.9875\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01136\n",
            "Epoch 45/200\n",
            " - 7s - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0129 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01136\n",
            "Epoch 46/200\n",
            " - 7s - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0126 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01136\n",
            "Epoch 47/200\n",
            " - 7s - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0253 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01136\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
            "Epoch 48/200\n",
            " - 7s - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0090 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.01136 to 0.00898, saving model to /content/drive/My Drive/CMATERdb/model_1.048-0.00792.hdf5\n",
            "Epoch 49/200\n",
            " - 7s - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0126 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00898\n",
            "Epoch 50/200\n",
            " - 7s - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00898\n",
            "Epoch 51/200\n",
            " - 7s - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0188 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00898\n",
            "Epoch 52/200\n",
            " - 7s - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0182 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00898\n",
            "Epoch 53/200\n",
            " - 7s - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0122 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00898\n",
            "Epoch 54/200\n",
            " - 7s - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0155 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00898\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
            "Epoch 55/200\n",
            " - 7s - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.00898 to 0.00757, saving model to /content/drive/My Drive/CMATERdb/model_1.055-0.00823.hdf5\n",
            "Epoch 56/200\n",
            " - 7s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0118 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00757\n",
            "Epoch 57/200\n",
            " - 7s - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00757\n",
            "Epoch 58/200\n",
            " - 7s - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00757\n",
            "Epoch 59/200\n",
            " - 7s - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0100 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00757\n",
            "Epoch 60/200\n",
            " - 7s - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0152 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00757\n",
            "Epoch 61/200\n",
            " - 7s - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00757\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
            "Epoch 62/200\n",
            " - 7s - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0127 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00757\n",
            "Epoch 63/200\n",
            " - 7s - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00757\n",
            "Epoch 64/200\n",
            " - 7s - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00757\n",
            "Epoch 65/200\n",
            " - 7s - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00757\n",
            "Epoch 66/200\n",
            " - 7s - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00757\n",
            "Epoch 67/200\n",
            " - 7s - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0105 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00757\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
            "Epoch 68/200\n",
            " - 7s - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0110 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00757\n",
            "Epoch 69/200\n",
            " - 7s - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0087 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00757\n",
            "Epoch 70/200\n",
            " - 7s - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.00757 to 0.00671, saving model to /content/drive/My Drive/CMATERdb/model_1.070-0.00354.hdf5\n",
            "Epoch 71/200\n",
            " - 7s - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0092 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00671\n",
            "Epoch 72/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00671\n",
            "Epoch 73/200\n",
            " - 7s - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00671\n",
            "Epoch 74/200\n",
            " - 7s - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0111 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00671\n",
            "Epoch 75/200\n",
            " - 7s - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00671\n",
            "Epoch 76/200\n",
            " - 7s - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0167 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00671\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
            "Epoch 77/200\n",
            " - 7s - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00671\n",
            "Epoch 78/200\n",
            " - 7s - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0185 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00671\n",
            "Epoch 79/200\n",
            " - 7s - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00671\n",
            "Epoch 80/200\n",
            " - 7s - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0102 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00671\n",
            "Epoch 81/200\n",
            " - 7s - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.00671 to 0.00587, saving model to /content/drive/My Drive/CMATERdb/model_1.081-0.00660.hdf5\n",
            "Epoch 82/200\n",
            " - 7s - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00587\n",
            "Epoch 83/200\n",
            " - 7s - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0084 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00587\n",
            "Epoch 84/200\n",
            " - 7s - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00587\n",
            "Epoch 85/200\n",
            " - 7s - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00587\n",
            "Epoch 86/200\n",
            " - 7s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0073 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00587\n",
            "Epoch 87/200\n",
            " - 7s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.00587 to 0.00573, saving model to /content/drive/My Drive/CMATERdb/model_1.087-0.00286.hdf5\n",
            "Epoch 88/200\n",
            " - 7s - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00573\n",
            "Epoch 89/200\n",
            " - 7s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00573\n",
            "Epoch 90/200\n",
            " - 7s - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0080 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00573\n",
            "Epoch 91/200\n",
            " - 7s - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0083 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00573\n",
            "Epoch 92/200\n",
            " - 7s - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00573\n",
            "Epoch 93/200\n",
            " - 7s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00573\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
            "Epoch 94/200\n",
            " - 7s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0098 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00573\n",
            "Epoch 95/200\n",
            " - 7s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00573\n",
            "Epoch 96/200\n",
            " - 7s - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00573\n",
            "Epoch 97/200\n",
            " - 7s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00573\n",
            "Epoch 98/200\n",
            " - 7s - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00573\n",
            "Epoch 99/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.00573 to 0.00542, saving model to /content/drive/My Drive/CMATERdb/model_1.099-0.00242.hdf5\n",
            "Epoch 100/200\n",
            " - 7s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00542\n",
            "Epoch 101/200\n",
            " - 7s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00542\n",
            "Epoch 102/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00542\n",
            "Epoch 103/200\n",
            " - 7s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00542\n",
            "Epoch 104/200\n",
            " - 7s - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00542\n",
            "Epoch 105/200\n",
            " - 7s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00542\n",
            "\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
            "Epoch 106/200\n",
            " - 7s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00542\n",
            "Epoch 107/200\n",
            " - 7s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.00542\n",
            "Epoch 108/200\n",
            " - 7s - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.00542\n",
            "Epoch 109/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.00542\n",
            "Epoch 110/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.00542\n",
            "Epoch 111/200\n",
            " - 7s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0054 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.00542 to 0.00535, saving model to /content/drive/My Drive/CMATERdb/model_1.111-0.00188.hdf5\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
            "Epoch 112/200\n",
            " - 7s - loss: 9.3093e-04 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.00535 to 0.00478, saving model to /content/drive/My Drive/CMATERdb/model_1.112-0.00093.hdf5\n",
            "Epoch 113/200\n",
            " - 7s - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.00478\n",
            "Epoch 114/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.00478\n",
            "Epoch 115/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0055 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.00478\n",
            "Epoch 116/200\n",
            " - 7s - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.00478\n",
            "Epoch 117/200\n",
            " - 7s - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0064 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.00478\n",
            "Epoch 118/200\n",
            " - 7s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.00478\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
            "Epoch 119/200\n",
            " - 7s - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0092 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.00478\n",
            "Epoch 120/200\n",
            " - 7s - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.00478\n",
            "Epoch 121/200\n",
            " - 7s - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.00478\n",
            "Epoch 122/200\n",
            " - 7s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.00478\n",
            "Epoch 123/200\n",
            " - 7s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.00478\n",
            "Epoch 124/200\n",
            " - 7s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0073 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.00478\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
            "Epoch 125/200\n",
            " - 7s - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.00478\n",
            "Epoch 126/200\n",
            " - 7s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.00478\n",
            "Epoch 127/200\n",
            " - 7s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.00478\n",
            "Epoch 128/200\n",
            " - 7s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0070 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.00478\n",
            "Epoch 129/200\n",
            " - 7s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0072 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.00478\n",
            "Epoch 130/200\n",
            " - 7s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0075 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.00478\n",
            "\n",
            "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
            "Epoch 131/200\n",
            " - 7s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 0.9970\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.00478\n",
            "Epoch 132/200\n",
            " - 7s - loss: 9.5298e-04 - accuracy: 0.9998 - val_loss: 0.0065 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.00478\n",
            "Epoch 133/200\n",
            " - 7s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.00478\n",
            "Epoch 134/200\n",
            " - 7s - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.00478\n",
            "Epoch 135/200\n",
            " - 7s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.00478\n",
            "Epoch 136/200\n",
            " - 7s - loss: 6.3407e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.00478\n",
            "\n",
            "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
            "Epoch 137/200\n",
            " - 7s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.00478\n",
            "Epoch 138/200\n",
            " - 7s - loss: 7.4232e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.00478\n",
            "Epoch 139/200\n",
            " - 7s - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.00478\n",
            "Epoch 140/200\n",
            " - 7s - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.00478\n",
            "Epoch 141/200\n",
            " - 7s - loss: 8.4724e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.00478\n",
            "Epoch 142/200\n",
            " - 7s - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.00478\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
            "Epoch 00142: early stopping\n",
            "4000/4000 [==============================] - 1s 362us/step\n",
            "Loss: 0.0060  Accuaracy: 99.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEJUXL4myc97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "a9b99a7d-0aa0-4697-83c7-d82c26f920f4"
      },
      "source": [
        "from sklearn.metrics import classification_report,precision_score,recall_score,accuracy_score,f1_score,cohen_kappa_score\n",
        "yhat_probs = s1.model.predict(Xtest)\n",
        "yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "Y_real = np.argmax(Ytest, axis=1)\n",
        "print(\"recall : \",recall_score(Y_real,yhat_classes, average='macro'))\n",
        "print(\"precision : \", precision_score(Y_real, yhat_classes, average='macro'))\n",
        "print(\"f1 score: \",f1_score(Y_real, yhat_classes , average='macro'))\n",
        "print(\"cohen_kappa_score: \",cohen_kappa_score(Y_real, yhat_classes))\n",
        "print(\"Classification report: \\n\",classification_report(Y_real, yhat_classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall :  0.998\n",
            "precision :  0.9980061971693335\n",
            "f1 score:  0.99799936053987\n",
            "cohen_kappa_score:  0.9977777777777778\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       400\n",
            "           1       1.00      0.99      0.99       400\n",
            "           2       1.00      1.00      1.00       400\n",
            "           3       0.99      1.00      1.00       400\n",
            "           4       1.00      1.00      1.00       400\n",
            "           5       1.00      1.00      1.00       400\n",
            "           6       1.00      1.00      1.00       400\n",
            "           7       1.00      1.00      1.00       400\n",
            "           8       1.00      1.00      1.00       400\n",
            "           9       1.00      1.00      1.00       400\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       1.00      1.00      1.00      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI6JPbm2-VFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "0f03f797-6e5a-4d6b-ebd0-57f0c0a2b093"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "test_preds = s1.model.predict(Xtest)\n",
        "test_classes = [np.argmax(x) for x in Ytest]\n",
        "test_y_real = [np.argmax(x) for x in test_preds]\n",
        "#from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "cm=confusion_matrix(test_y_real, test_classes)\n",
        "# Transform to df for easier plotting\n",
        "cm_df = pd.DataFrame(cm,dtype=np.int32,\n",
        "                     index = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'], \n",
        "                     columns = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(cm_df, annot=True,fmt=\"d\")\n",
        "#plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "print(s1.model.history.history.keys())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLfVPrwgFFmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "550ef004-adf7-4c61-f998-dd16a8b029b3"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "test_preds = s1.model.predict(Xtest)\n",
        "test_classes = [np.argmax(x) for x in Ytest]\n",
        "test_y_real = [np.argmax(x) for x in test_preds]\n",
        "#from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "cm=confusion_matrix(test_y_real, test_classes)\n",
        "# Transform to df for easier plotting\n",
        "cm_df = pd.DataFrame(cm,dtype=np.int32,\n",
        "                     index = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'], \n",
        "                     columns = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(cm_df, annot=True,fmt=\"d\")\n",
        "#plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "print(s1.model.history.history.keys())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}